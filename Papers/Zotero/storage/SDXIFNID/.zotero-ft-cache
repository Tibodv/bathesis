Current Psychology (2024) 43:23656–23674 https://doi.org/10.1007/s12144-024-06072-8
Chatbots have the potential to move user interaction beyond classroom boundaries in education. Chatbots can support learning satisfaction by providing feedback and personalized learning (Hwang et al., 2020; Pérez et al., 2020). In learning subjects, chatbots promote students' learning, communication, problem solving, creativity, and other types of development (Sung et al., 2016). As stated by Lee et al. (2022), chatbots provide students with the opportunity to ask questions and discuss topics, providing a sense of active participation in the learning process and creating a studentcentered environment by enabling in-depth discussions. It can be emphasized that the use of chatbots in education can provide benefits such as increasing students' interest and concentration by allowing them to review the learning content repeatedly and contribute to permanent learning (Bii et al., 2018; Fryer et al., 2019; Ramandanis & Xinogalos, 2023). Moreover, chatbots can help to provide relaxing and friendly interaction (Ochoa & Wise, 2021). In order to make the support of chatbots to education easier, more effective and continuous, it is important to
Introduction
A chatbot is a software application that can recognize text or voice and respond with text and voice (Aksu Dünya & Yıldız Durak, 2023). Shah et al. (2016) stated that artificial intelligence (AI)-powered chatbots are software that offer personalized applications that use semantic analysis and natural language processing (NLP) techniques to perform text and voice communications, understand user commands, and create rapid interaction with specified expressions.
Hatice Yildiz Durak hatyil05@gmail.com
Aytuğ Onan
aytug.onan@ikcu.edu.tr
1 Department of Educational Science, Eregli Faculty of Education, Necmettin Erbakan University, Konya, Turkey
2 Department of Computer Engineering, Software Engineering, Izmir Katip Celebi University, İzmir, Turkey
Abstract
Adopting innovations in educational practice is a challenging task. In order to promote the use of technological innovations, acceptance of the technology by potential users is a prerequisite. Indeed, understanding the various factors that influence technology acceptance is critical for technology acceptance research. The use and acceptance of chatbots in education as a technological innovation is a topic that needs to be investigated. Chatbots, which offer close to human interaction between the user and technology through text and voice, can provide significant benefits in educational environments. The UTAUT2 model (extending UTAUT), which is widely used to evaluate technology acceptance, can serve as a framework for evaluating the acceptance and use of chatbots. This study aims to predict factors influencing students' use of chatbots in education within the UTAUT2 framework. PLS-SEM and machine learning tested the model, involving 926 students. According to the findings of the study, behavioral intentions were influenced by various factors including performance expectations and attitudes. Facilitating conditions and intentions significantly impacted chatbot usage time. Moderator effects were observed with age, gender, and usage experience affecting behavioral intentions. Support vector machine and logistic regression showed high prediction accuracies for behavioral intentions and usage time, respectively. These results provide insights for chatbot designers to meet user needs in educational settings.
Keywords Chatbot technology · UTAUT2 · Educational chatbot usage · Usage intensity · PLS-SEM · Machine learning algorithms
Accepted: 29 April 2024 / Published online: 21 May 2024 © The Author(s) 2024
Predicting the use of chatbot systems in education: a comparative approach using PLS-SEM and machine learning algorithms
Hatice Yildiz Durak1 · Aytuğ Onan2
13


Current Psychology (2024) 43:23656–23674
determine the acceptance and usage status of users. However, the acceptance of innovations in educational practices is often a challenging process (Yildiz Durak & Onan, 2023b, d). There is a lack of knowledge about what emerging technologies are and how to use them. Therefore, to promote the use of technological innovations, the process of accepting the relevant technology is an important prerequisite by users. Understanding the various factors affecting technology acceptance plays a critical role for technology acceptance research (Yildiz Durak, 2019, 2023). The use and acceptance of a technological innovation such as a chatbot in education is an important topic to be explored (Ragheb et al., 2022). Therefore, it is necessary to investigate this issue and contribute to the theoretical infrastructure through modeling studies. This study will make important contributions to the literature in this field.
In the acceptance of new technologies such as chatbots in education, various models have been developed to analyze how individuals who use the technology accept and intend to use it. These models are important in explaining the importance of subjective factors in determining users' actions and expectations about these actions and in structuring expectations. Theory of Acceptance and Use of Technology (UTAUT) model (Venkatesh et al., 2003) is based on the fact that behavioral intention to use a particular technology and actual usage behavior are explained by key factors such as performance expectancy, effort expectancy, social influence and facilitating conditions. UTAUT has been widely used to understanding and predicting user acceptance and usage behavior of various new technologies in education. The UTAUT2 model was proposed by Venkatesh et al. (2012). UTAUT2 provides a more comprehensive framework to explain the adoption and use of new technologies in contemporary contexts based on the UTAUT framework. UTAUT 2 extends the UTAUT model and adds additional factors to it. UTAUT 2 includes all four core factors of the previous model (performance expectancy, effort expectancy, social influence and facilitating conditions) and adds factors such as self-efficacy, anxiety and intention. This expanded construct can help researchers and practitioners better understand the acceptance of new technologies such as chatbots and develop more effective strategies to encourage users to adopt the technology. In short, UTAUT2 has a framework that aims to explain technology acceptance in a more comprehensive way. In addition, the UTAUT2 model recognizes the moderating effects of individual differences, including age, gender, education, and experience. Given the multifaceted nature of users' interactions with chatbots, it is important to consider various demographic and experiential factors (age, gender, education and experience) that may drive the relationship between users' behavioral intentions and actual usage behavior. Indeed, in
the context of the UTAUT2 construct, these variables are included in the model as moderators. In line with many studies investigating the acceptance and use of new technologies (e.g. Yildiz Durak, 2019), in this study we extend the UTAUT2 model to include moderators such as age, gender, education, and experience. These variables were chosen because of their potential influence on individuals' perceptions, attitudes, and behaviors towards technology adoption and use. In this way, it may be possible to understand how demographic and experiential factors interact with users' intentions and gain more in-depth insights into the dynamics of chatbot adoption and use. Using the UTAUT2 model (Venkatesh et al., 2012) as the theoretical framework, we investigated the determinants that promote or inhibit acceptance and use. This model is extended by integrating the system variables "chatbot quality and use continuity" introduced by Li et al. (2021) and Nguyen et al. (2021) in the chatbot field, seeing them as a potential precursor within the model.
Theoretical and conceptual framework
UTAUT 2 model
This study tests a model of pre-service teachers' acceptance of chatbot technology in education based on UTAUT2. From a theoretical perspective, there has been a focus on technology acceptance research and specifically on UTAUT2 for the consumer context (Venkatesh et al., 2012). This theoretical perspective allows to develop a model that explains the adoption of chatbots such as ChatGPT in the context of educational services based on UTAUT2.
The unified model of technology acceptance and use UTAUT2 is structured by Venkatesh et al. (2012) restructuring UTAUT by putting the consumer in focus. In this study, constructs such as attitude toward learning, self-efficacy, and anxiety were used in UTAUT 2. In addition to age, gender, chatbot usage experience modifier variables, chatbot confirmation and usage continuance, information and system quality, satisfaction and interaction preference structures that predict intention have been added. Previous studies have utilized the UTAUT2 framework in various contexts. For instance, Ragheb et al. (2022) developed a framework to explore higher education students' behavioral intentions towards adopting chatbot technology within the UTAUT framework. Mohd Rahim et al. (2022) adapted the UTAUT2 model within the information systems theory to investigate the factors influencing the effectiveness of chatbot adoption at the graduate level. Annamalai et al. (2023) assessed the adoption of chatbot usage in teaching English to university students. UTAUT2 is presently employed in examining
13
23657


Current Psychology (2024) 43:23656–23674
emerging AI tools and their early adopters, such as chatbots, virtual assistants (Mohd Rahim et al., 2022), recommendation systems, and predictive analytics tools (Raffaghelli et al., 2022; Wang et al., 2015). When scrutinizing new technologies such as AI, the UTAUT2 model serves to identify factors influencing early adoption, including perceived usefulness, ease of use, and social influence. By comprehending these factors, insights into the motivations behind technology adoption can be gleaned, and potential barriers to adoption can be identified (Menon & Shilpa, 2023). This research uses eight important UTAUT2 (performance expectancy, effort expectancy, attitude, social influence, facilitating conditions, self-efficacy, anxiety and intention) constructs to identify how the intention to continue using chatbot services is instilled in educational settings.
Performance expectancy (PE) It is the degree of belief that individuals will contribute to their performance by using technology (Venkatesh et al., 2003). Thus, performance expectancy is related to the level to which the individual believes that using the system will help them achieve performance gains. Performance expectancy has been shown to positively influence technology adoption in contexts such as chatbots (Kasilingam, 2020; Melián-González et al., 2021; Ragheb et al., 2022). Goal achievement is the focus of scaffolding, which supports improved performance, progress and achieving results (Terblanche & Kidd, 2022). In this study, performance expectation is considered as users' feelings about the chatbot tool that will help them reach the definitive answer. Accordingly, the following hypothesis was formulated:
H1. Performance expectancy positively affects behavioral intention to use and learn chatbots.
Effort expectancy (EE) It is the degree of belief and perception about the ease of use of technology (Venkatesh et al., 2003). The easier people perceive an application or technology to be to use, the more likely they are to use it. Previous studies (e.g. Almahri et al., 2020) found a positive relationship between effort expectancy and behavioral intention in chatbot use. On the other hand, Terblanche and Kidd (2022) stated that users may be willing to expend some degree of effort in exchange for a tangible outcome in chatbot use, and the amount of effort required to use the chatbot may trigger a lack of instant gratification. Therefore, there are contradictory findings in the literature. Therefore, it is thought that this relationship should be supported by new studies.
In this study, effort expectancy is considered as the degree of the user's perception of using the chatbot effortlessly and
how easy it is to use a chatbot. Accordingly, the following hypothesis was formulated:
H2. Effort expectancy positively influences behavioral intention to use chatbots and learn.
Attitude toward improving education (ATIE) Attitude was evaluated as the approach taken to experiencing new experiences in a task. Kasilingam (2020) emphasizes that the evaluation scheme of the consequences of performing a certain behavior, called attitude, has a direct relationship with elements such as behavioral intention. In short, attitude can be referred to as users' negative or positive emotions regarding the use of chatbots for education. Based on the views suggesting that attitude significantly affects individual behavioral intentions, it was deemed necessary to investigate the function of attitude in the acceptance of chatbot technology.
In this context, it is assumed that this study has a positive and repulsive effect on students' behavioral intentions to learn and use chatbots. Accordingly, the following hypotheses are formulated:
H3. Attitude towards improving learning positively affects behavioral intention to use chatbots and learn.
Social influence (SI) It emphasizes the importance of others in determining whether a user will adopt a particular technology. Social influence is thus the degree to which an individual perceives that significant others believe that he or she should use the new system (Venkatesh et al., 2003). This context is also related to how a person perceives his/ her image or status within a group. Some studies in the literature have emphasized that SI is important for the user's intention to use the particular technology (Jowarder, 2023; Raman & Don, 2013; Yildiz Durak, 2019). In this study, the following hypothesis was formulated to examine the effects of social influence on students' willingness to use chatbots:
H4. Social influence positively influences behavioral intention to use chatbots and learn.
Facilitating conditions (FC) It is the extent to which an individual believes that the organizational and technical infrastructure exists to support technology use (Venkatesh et al., 2003). Facilitating conditions express an individual's belief that technology and institutional infrastructure exist in such a way as to enable the use of technology. In this study, it is assumed that facilitating conditions have a beneficial effect on university students' behavioral intentions to learn and use
13
23658


Current Psychology (2024) 43:23656–23674
requires technology interaction, and therefore negative thoughts such as anxiety may hinder task performance.
In this study, the following hypotheses are formulated to address the potential of anxiety in explaining their intention to use and learn chatbot technology:
H7. Anxiety negatively influences behavioral intention to use chatbots and learn.
Behavioral intention to use/Learn chatbot (BIULC) An individual intends to perform a given task, and in this study, the behavioral intention to use and learn chatbots is discussed. Based on the view that behavioral intention is the most important descriptor of actual use, the following hypotheses are formulated:
H8. Behavioral intention to use and learn chatbot positively affects chatbot usage time.
Differences in chatbot usage by gender, age, and experience
Age differences can be a determining factor in technology use (Durak & Durak, 2020). According to van der Goot and Pilgrim (2019), it is important to examine age-related differences so that customers of all ages in different fields are satisfied with chatbot services and feel alienated from chatbot communication. Furthermore, research on age-related variances in perceptions of chatbot communication, within the framework of socio-emotional selectivity theory, indicates that older and younger adults do not perceive safety in the use of new technologies in the same way. This variation is influenced by age-related motivations, changes in social preferences, and intentions concerning technology acceptance and usage. In a study by Terblanche and Kidd (2022), age had a moderator effect on effort expectancy. In conclusion, motivations for using chatbots may differ depending on age. Chatbot technology is a new and rapidly spreading technology. A limited number of studies have investigated the regulatory effects of this technology on acceptance intentions and behaviors in the context of age and gender. Kasilingam (2020) highlighted that chatbots are seen as less risky by male participants than female participants in the field of e-commerce. In the study conducted by Yildiz Durak (2019), gender plays an important role in the behavior of adopting and using technology and gender has psychological effects on the acceptance process.
Age and gender have an important place in UTAUT studies in various technological environments such as chatbots.
chatbots and their duration of use. Accordingly, the following hypotheses are formulated:
H5a. Facilitating conditions positively influence behavioral intention to use and learn chatbots.
H5b. Facilitating conditions positively affect chatbot usage time.
Self-efficacy (SE) Self-efficacy is based on two theories. These are: social cognitive theory (Bandura, 1989) and self-efficacy theory (Bandura, 1977). Self-efficacy can be explained by individuals learning to process cognitive, personal, and environmental factors to determine motivation and behavior (Crothers et al., 2020). According to the self-efficacy theory, self-efficacy explains that self-efficacy is the self-motivated belief that one can accomplish a task (Bandura, 2012). Self-efficacy has been evaluated as a structure that affects the individual's time, effort, and belief level, resistance to coping with difficulties, and the time spent on accomplishing a task. According to various studies, the importance of self-efficacy to fulfill any task within the UTAUT2 framework is supported (e.g. Yildiz Durak, 2019). Balakrishnan et al. (2022) also addressed social self-efficacy and reflected on chatbot acceptance and use from an interaction perspective. This study introduces self-efficacy as a predictor in the UTAUT2 model to understand user and system user confidence to behave with the intention to continue using chatbots for educational purposes. In this context, it is assumed that this study has a positive and repulsive effect on students' behavioral intentions to learn and use chatbots. Accordingly, the following hypotheses are formulated:
H6. Self-efficacy positively influences behavioral intention to use and learn chatbots.
Anxiety (An) It is a concept that emphasizes users' concerns about using and accepting technology (Mokmin & Ibrahim, 2021). Bandura (1986) defines anxiety as a negative emotional reaction or state that negatively affects one's intention to perform a certain task. Anxiety can also be an important barrier to the acceptance of information technologies. Anxiety has been found to negatively affect an individual's performance expectations in relation to technology use (e.g. Gunasinghe & Nanayakkara, 2021; Gunasinghe et al., 2019). In addition, anxiety can negatively affect the perceived effort to complete a task in technological environments (Çelik, 2016). Chatbots are an environment that
13
23659


Current Psychology (2024) 43:23656–23674
theoretical foundations of the expectation-confirmation model (ECM) to explain how consumers of digital technology products or services decide to continue using (or repurchase) a product they have previously adopted (or purchased) (Liao et al., 2010). This model includes users' confirmation after use, perceived usefulness, satisfaction, and motivation to continue using a technology. In addition, this model assumes that users expect a certain level of performance from the technology when they start using a product/ service or even before they start it. Meeting expectations creates positive intention and satisfaction. This satisfaction allows users to continue using or retry/buy the technology (Li et al., 2021). The scope of this study is to determine the sustainability of chatbot confirmation and use and to review its impact on intent. In this context, the following hypothesis has been formulated:
H12. Chatbot confirmation and sustainability of use positively influence behavioral intention to use and learn chatbots.
Chatbot system, ınformation, and service quality
Nguyen et al. (2021) emphasized that system, information, and service quality are important to address quality dimensions related to chatbot services. This framework is discussed in this study. Information is important in determining the quality dimensions of systems. Relevance, accuracy, quantity, reliability, and readability are important quality characteristics of information (Li et al., 2021). Later, the perception of service quality takes place in the quality dimension as it is seen as an important factor for the services and the system to differentiate from their competitors (Parasuraman et al., 1988). In this context, the following hypothesis has been formulated:
H12. Chatbot systems, information, and service quality positively affect behavioral intention to use and learn chatbots.
Chatbot satisfaction
Satisfaction is important for the intention of meeting their thoughts and expectations in the use of a system and sustainability of use. Indeed, Martín-Rodriguez et al. (2015) mentioned the relationship between high satisfaction in the learning process and high academic achievement and performance. Determining satisfaction levels in chatbot systems and examining them as factors affecting intention behaviors provide data to organize chatbots more effectively
Considering the expected moderator effect of gender and age, the following hypotheses are proposed:
H9a. Age strengthens the relationship between performance expectancy and behavioral intention to use/learn chatbots.
H9b. Age strengthens the relationship between effort expectancy and behavioral intention to use/learn chatbots.
H9c. Age strengthens the relationship between social influence and behavioral intention to use/learn chatbots. H10a. Gender strengthens the relationship between performance expectation and behavioral intention to use chatbots/learn.
H10b. Gender strengthens the relationship between effort expectancy and behavioral intention to use chatbots/ learn. H10c. Gender strengthens the relationship between social influence and behavioral intention to use chatbots/learn.
In systems where interaction is a priority, user experience is decisive in the adoption of the system by users (Følstad & Brandtzaeg, 2020; Hornbæk & Hertzum, 2017). User experience can be shaped according to the content of technology, system interactions, and system control. On the other hand, user experience can be examined from different perspectives. In this study, the experience of users is considered as the duration of continuous use of chatbot systems. This study examines the role of a moderator to support the understanding of the importance of chatbot user experience. Considering the expected moderator effect of the chatbot usage experience, the following hypotheses are proposed:
H11a. Chatbot usage experience strengthens the relationship between performance expectation and behavioral intention to use/learn chatbots. H11b. Chatbot usage experience strengthens the relationship between effort expectancy and behavioral intention to use chatbots/learn. H11c. Chatbot usage experience strengthens the relationship between social influence and behavioral intention to use chatbots/learn.
Chatbot confirmation and usage continuance
What is the factor that enables users to continue using chatbot features in different areas is an important issue waiting to be determined. In this study, chatbot confirmation and usage continuance are discussed as variables that affect the behavioral intention of the UTAUT2 model. This structure was described by Li et al. (2021) in the context of the framework proposed. This structure uses the
13
23660


Current Psychology (2024) 43:23656–23674
Method
Research model
This research is exploratory quantitative research that analyzes data from a database obtained from a data collection tool based on a cross-sectional UTAUT2 framework. In the research, a model has been proposed within the framework of UTAUT 2. The model presented in Fig. 1 shows 12 key relationships (represented by pathway diagrams) and 3 moderator relationships corresponding to the stated hypotheses of the study. The proposed model suggests that chatbot usage intention is supported by the expanded UTAUT 2 model with the constructs of confirmation, quality, satisfaction, and interaction preference in chatbot usage.
Participants
926 students participated in the study. 5 participants were excluded from the study due to loss of data in their questionnaires. Participants were from the universities of many cities in Turkey. In addition, the socio-economic levels of the participants are at medium level. Participants were included in the research using the convenience sampling method. In this method, the researcher selects a sample that is easy to
and efficiently as a training tool. In this study, the effect of chatbot usage satisfaction on chatbot learning and usage behavior intention was investigated. In this context, the following hypothesis has been proposed:
H13. Satisfaction with using chatbot positively affects behavioral intention to use chatbot and learn.
Interaction preference in chatbot usage
Chatbots are more cost-effective and time-efficient than human agents. However, some studies have concluded that users still prefer human-agent chatbots (eg Prentice & Nguyen, 2021). Luo et al. (2019) emphasized that even though chatbots are more effective than human agents, they are preferred by users in receiving services. The intense interest in artificial intelligence-based bots such as ChatGPT affects the preferability of chatbots. In this context, the effect of chatbot usage preference on chatbot learning and usage behavior intention was investigated in this study. In this context, the following hypothesis has been proposed:
H14. Interaction preference positively influences behavioral intention to use and learn chatbots.
Fig. 1 Research model
13
23661


Current Psychology (2024) 43:23656–23674
The implementation process included how to prepare educational discussions more accurately by giving certain prompts. Students searched for answers by entering specific prompts, keywords, or questions. Participants both interacted with at least 10 prompts about the course topics by subscribing to the artificial intelligence-based ChatGPT (https://chat.openai.com) environment and interacted with the Telegram-based environment created by the researchers in the FlowXO (https://flowxo.com) environment. After this experience, which took about 60 min for each participant, they completed the survey. The chatbot created by the researchers did not provide any informational content. This environment provides answers to the basic questions determined by the researcher was asked (What is a chatbot?, Why should I use a chatbot when I am a teacher?, How can I use the chatbot in education?, Can the chatbot be used in all age groups?, Is the chatbot suitable for which education levels?). FlowXO is an environment that is distributed over platforms such as Facebook Messenger, Whatsapp, Telegram, and Slack can be streamed with a free membership. In this research, a text-based chatbot was created. ChatGPT, on the other hand, is a chatbot developed by OpenAI company and supported by artificial intelligence.
Data collection tools
Personal information form There are 8 questions in this form. This form was created to collect data about gender, age, grade, chatbot usage preferences, etc.
Behavioral intention scale for using/Learning chatbots in education This scale was originally developed by Mokmin and Ibrahim (2021) and adapted into Turkish by Yildiz Durak and Onan (2023d). This scale consists of 24 items. The scale is a 7-point Likert type. The sub-dimensions in the scale are as follows: “performance expectancy, effort expectancy, attitude toward improving education, social influence, facilitating conditions, self-efficacy, anxiety, behavioral intention to use/learn chatbot”. The Cronbach's alpha coefficients calculated for the sub-dimensions of the
access in terms of time and place, and this method is often used when the researcher does not have the opportunity to use other sampling methods. With this sampling method, an attempt was made to reach a high number of participants to reduce the possibility of bias. Informed consent was obtained from the participants. Students who did not volunteer to participate in the study and did not want to continue the study were excluded from all stages of the application process. In the study, participants were interacted with online or face to face, depending on the availability of the participants. 69.3% of the university students participating in the research are female and 30.7% are male. The average age of the participants is 21.11 (SD = 2.331, Median = 21.00). User chatbot usage experience is 1.2 years in years. The satisfaction level of users from the feedback received from chatbots is 2.66 out of 4. Chatbot usage frequency was stated as 58.2% "rarely" with the highest rate.
Procedures
Participants in the study followed the procedures individually, using free ChatGPT 3.5 and the word-based flow chatbot via the Telegram environment. Figure 2 summarizes the procedures followed in this research. First, participants were given a seminar lasting approximately 45 min, providing information about the purpose of the study and the introduction of the environments to be used. It was explained to the participants that they had the right to withdraw at any stage of the study and their informed consent was obtained. For approximately 25 min, ChatGPT was introduced to the participants, and information was given about the basic functions of the environment, such as how to create an account on this environment, how to access this environment, how to give prompts, and how to access dialogue histories. In the rest of the session, which lasted approximately 45 min, the chatbot account created in the Telegram instant messaging application was shown and the types of questions included in this environment were introduced. Those who did not have this application were allowed to download the application and log in.
Fig. 2 Procedures of the research
13
23662


Current Psychology (2024) 43:23656–23674
Bayes, k-Nearest Neighbor (k-NN), support vector machine (SVM), Random Forest, and logistic regression classifiers. In this manuscript, we have utilized several conventional machine learning algorithms to predict the use of chatbots in education due to their robustness and effectiveness in handling complex data. Comparing different algorithms helps validate the consistency of predictive accuracies, ensuring robust conclusions. Algorithms like SVM and logistic regression are selected for their ability to provide stable predictions across high-dimensional data. SVM can handle non-linear relationships, which are common in educational data, through kernel methods. Using multiple algorithms, including k-Nearest Neighbors and Random Forest, we have performed a thorough and varied analysis of the data, enhancing the reliability of predictions. The analysis procedure is presented in Fig. 3 Before using machine learning algorithms, the preliminary examination of the data was carried out. At this stage, the scores obtained by the participants from the scales were converted into z-scores. Then, categorical variables such as gender were transformed into dummy variables.
PLS-SEM algorithm In this study, the PLS-SEM approach was preferred to test a model theoretically based on UTAUT2. In the PLS-SEM method, the measurement model is tested in the first step. The structural model is evaluated when the measurement model provides the necessary assumptions. In this study, this method was deemed appropriate due to the complex design of the research model. PLS-SEM can provide effective results with smaller sample sizes compared to the covariance-based structural equation modeling method (Hair et al., 2019). PLS-SEM achieves high statistical power with relatively small sample sizes (Hair et al., 2017). The assumptions of PLS-SEM regarding data distribution are limited, it does not assume that the data are normally distributed, and it is successful in explaining skewed and non-normal data (Hair et al., 2011). In addition, PLS-SEM can easily work to explain the observable variable with latent structures without imposing constraints on the model.
Machine learning algorithms In this study, k-NN, support vector machine (SVM), naive bayes classifier, logistic regression, and random forest algorithms were used as estimation and classification techniques used for the research model.
k-Nearest Neighbor (K-NN) This algorithm is a filtering technique and is the most widely used algorithm in machine
scale are 0.945, 0.949, 0.943, 0.897, 0.0.894, 0.938, 0.895, and 0.942, respectively. (See Appendix Table 5).
Chatbot confirmation and usage continuance scale This scale was adapted by Yildiz Durak and Onan (2023a), based on the framework proposed by Li et al. (2021). The scale is a 7-point Likert type. The sub-dimensions in this scale are “confirmation, understandability, reliability, responsiveness, assurance/ trust, interactivity”. The Cronbach's alpha coefficients calculated for the scale is 0.978 (See Appendix Table 5).
Chatbot system, information and service quality scale This scale was adapted by Yildiz Durak and Onan (2023c) based on the framework proposed by Nguyen et al. (2021). The scale is a 7-point Likert type. The sub-dimensions of this scale are "information quality, system quality, and service quality". The Cronbach's alpha coefficients calculated for the scale is 0.965 (See Appendix Table 5).
Data set
Data collection
The data were collected with an electronic form containing Likert-type items in the data collection tool, whose validity and reliability were ensured. In the data collection tool, students' personal and private information such as name, identity, or school was not collected. The electronic link address of the prepared form was shared through social media and instant messaging applications. It was ensured that the students participated in the research on a completely voluntary basis. For the privacy policy, respondents who completed the survey were provided with a privacy statement on how their data would be used. In the context of anonymization, a survey design was presented that did not require personal information from the participants. The collected data is stored encrypted in the cloud system. No one has access to the data except the authors. Participants' data were only used by the authors to analyze or report.
Data analysis
In this study, two techniques were used to test the putative research model. At this stage, the analyzes were completed with SmartPLS 4 software, PLS-SEM, and Knime 4.7 using machine learning algorithms. In this context, the data were analyzed by comparative approaches with classifiers based on various classifiers, including PLS-SEM, Naive
13
23663


Current Psychology (2024) 43:23656–23674
(Cortes & Vapnik, 1995). SVM identifies data samples used for classification. The SVM algorithm creates a model that labels a dataset into a single class. It generates an optimized linear regression by matching the input vector with the training data consisting of the input matrix and an output vector. SVM performs linear and nonlinear classification and supports linear and nonlinear regression applications. This algorithm, which can work with high-dimensional data, can be preferred when the number of observations and features is high (Ray, 2019).
Naive bayes This algorithm has a simple structure. It is based on conditional probability. Therefore, the probability
learning. With this method, which is a type of supervised learning, the users in the data sets are classified according to their similarities in terms of different characteristics. This method uses a vector space model for classification. After the users are classified, new users are positioned to be neighbors with k-related users. That is, similarity to the properties of known classes is calculated to predict the probable class of unknown users. Distances between users are calculated using measurement methods such as cosine or Pearson similarity and Euclidean distance.
Support vector machine (SVM) The SVM algorithm was introduced to solve classification and regression problems
Fig. 3 Analysis procedure
13
23664


Current Psychology (2024) 43:23656–23674
Results
PLS-SEM
Measurement model
In the measurement model, convergent validity, discriminant validity, reliability, and multiple correlation were used and evaluated to verify the testability of the structural model. The findings are presented in Appendix Tables 4, 5, and 6. According to Appendix Table 4, factor loads are expected to be greater than 0.70 for convergent validity (Hair et al., 2017). All factors were found to be greater than 0.70. The values in Appendix Table 5 show that the values for construct reliability and validity are above the threshold values expected in the literature. The AVE values are above 0.50 and the Cronbach's alpha (CA) and composite reliability (CR) values for the reliability coefficients are above 0.70. HTMT ratios were used for the discriminant validity of the measurement model. Appendix Table 6 shows that this validity was achieved. In the measurement model in Appendix Table 6, HTMT values show that all values in this study provide discriminant validity, according to data on discriminant validity. Indeed, in the literature, it is recommended that the HTMT value is below 0.90 (Henseler et al., 2015). As a result, the validity and reliability of the tested measurement model are ensured in the context of research findings. Therefore, at the next stage, a suitable ground was created for the testing of the structural model.
Structural equation model
The validity of the measurement model was tested. Since the validity of the measurement model was ensured at this stage, the structural model was tested with the PLS-SEM algorithm. In this research, Bootstrapping was determined as 5000 subsamples, and analyses were made. The findings regarding the structural model are shown in Fig. 4 and Table 1. According to Fig. 3 and Table 1, behavioral intention to use/learn chatbot, performance expectancy, effort expectancy, attitude towards improving learning, self-efficacy, anxiety, and chatbot confirmation and usage continuance significantly affected (H1, H2, H3, H6, H7, and H12).
table and class probabilities are used to determine the probabilistic relationship between the structures. It can be used for Naive Bayes' binary and multiclass classification problems. To convert the nominal value into a form that the classifier can easily analyze the data, feature coding was done in the preprocessing step in Knime. In the Naive Bayes categorical classification, all data should be distributed in a discrete form concerning nominal values.
Logistic regression This algorithm is used to solve a classification problem. That is, this method is a useful analysis for classification problems where you are trying to determine whether a new sample best fits a category (Thomas & David, 2017). It models the probability (in terms of 0 and 1 (true/false, yes/no)) of whether an event will occur or not depending on the values of the input variables. The output of the logistic regression is the probability score of being included in a class. Therefore, to use it in solving a problem, it is important to obtain a cutoff point to classify the target.
Random forest (RF) The random forest algorithm is a prediction method categorized as ensemble learning that integrates multiple decision trees and trains each decision tree on a different observation sample over multiple deci sion trees. It can be used for classification, regression, and time series estimation (Breiman, 2001). It combines predictions from various decision trees to determine the final class of the test object. A sub-feature has a set of decision paths from the node to the last leaf. The estimation is the sum of individual characteristics and the average value of the top region covered by the training set. In this context, the number of trees in the forest and the number of variables used to develop each tree are two key features that affect the predictive capacity of the ran dom forest algorithm.
The metrics used to measure the performance of the classification model are accuracy, recall and precision. Among these metrics used to measure the performance of the classification model, accuracy is defined as the ratio of correct predictions to total predictions. Precision is defined as the ratio of correctly classified positive examples to the total number of positively predicted examples. Recall is defined as the ratio of correctly predicted positive instances to all positive instances.
13
23665


Current Psychology (2024) 43:23656–23674
coefficient between performance expectation and behavioral intention to use/learn chatbot (H11a). In addition, the percentage of variance explained was 76.0% for behavioral intention to use/learn chatbot, while it was 12.4% for chatbot usage time.
Examining the model with machine learning algorithms
In the research, accuracy, sensitivity, sensitivity, and crossaccuracy rates were calculated to determine the performance of the model. The values found are reported as the average of the accuracy results of the model created for the output variable.
The hypotheses that there is a relationship between behavioral intention to use/learn chatbots and social influence, facilitating conditions, chatbot system and information quality, the satisfaction of using the chatbot, and preference for interaction were rejected (H4, H5a, H13, H14, and H15). Facilitating conditions (H5b) and behavioral intention to use/learn chatbot (H8) were found to have significant effects on chatbot usage time.
Age was found to have a moderator effect on the path coefficient between performance expectation and behavioral intention to use/learn chatbots (H9c). Gender, on the other hand, has a moderator effect (H10a, b) on the path coefficient between performance and effort expectation and behavioral intention to use/learn chatbots. Chatbot usage experience has a positive moderator effect on the path
Fig. 4 Structural Equation Model. *PE: Performance Expectancy, EE: Effort Expectancy; ATIE: Attitude towards Improving Learning; SI: Social Influence; FC: Facilitating conditions; SE: Self Efficacy; An: Anxiety; BIULC: Behavioral Intention to Use/Learn Chatbot
13
23666


Current Psychology (2024) 43:23656–23674
the highest precision result is the support vector machines (0.969) algorithm. As a result of the sensitivity, the support vector machine algorithm (0.978) is the algorithm that gives the highest result.
The accuracy, precision, and sensitivity of the model between behavioral intention to use/learn chatbot and chatbot usage time
The findings for the accuracy of the model between behavioral intention to use/learn chatbot and duration of chatbot usage are presented in Table 3.
Accuracy, precision, and sensitivity of the model between research variables and behavioral intention to use/learn chatbots
The findings for the accuracy of the model between the research variables and the behavioral intention to use/learn chatbots are presented in Table 2. Looking at Table 2, the algorithm with the highest accuracy result according to the behavioral intention to use and learn chatbot is the support vector machine (0.975) algorithm. In the cross-accuracy results, support vector machine (0.986) gave the most accurate result. The algorithm with
Table 1 Hypothesis test results Path Original sample Standard deviation T statistics P values Decision H1 PE—> BIULC 0.178 0.067 2.674 0.008 Accepted H2 EE—> BIULC -0.170 0.068 2.517 0.012 Accepted H3 ATIE—> BIULC 0.218 0.060 3.621 0.000 Accepted H4 SI—> BIULC -0.003 0.041 0.066 0.948 Rejected H5a FC—> BIULC 0.083 0.052 1.596 0.111 Rejected H5b FC—> Chatbot Usage Time 0.231 0.047 4.896 0.000 Accepted H6 SE—> BIULC 0.324 0.055 5.923 0.000 Accepted H7 An—> BIULC 0.073 0.020 3.654 0.000 Accepted H8 BIULC—> Chatbot Usage Time 0.139 0.047 2.966 0.003 Accepted H9a Age x PE—> BIULC -0.027 0.047 0.571 0.568 Rejected H9b Age x EE—> BIULC -0.025 0.050 0.514 0.607 Rejected H9c Age x SI—> BIULC 0.061 0.019 3.240 0.001 Accepted H10a Gender x PE—> BIULC -0.219 0.100 2.197 0.028 Accepted H10b Gender x EE—> BIULC 0.244 0.101 2.411 0.016 Accepted H10c Gender x SI—> BIULC 0.033 0.055 0.608 0.543 Rejected H11a Chatbot Usage Experience x PE—> BIULC 0.097 0.046 2.127 0.033 Accepted H11b Chatbot Usage Experience x EE—> BIULC -0.074 0.049 1.486 0.137 Rejected H11c Chatbot Usage Experience x SI—> BIULC -0.014 0.025 0.569 0.569 Rejected H12 Sustainability of Use—> BIULC 0.232 0.049 4.777 0.000 Accepted H13 Quality—> BIULC 0.026 0.052 0.506 0.613 Rejected H14 Satisfaction—> BIULC -0.017 0.020 0.874 0.382 Rejected H15 Interaction Preference—> BIULC -0.020 0.017 1.179 0.238 Rejected
Table 2 Results of accuracy, accuracy, recall and cross- accuracy according to behavioral intention to use and learn chatbots Accuracy of the model
Cross accuracy
Precision of the model
Recall of the model
k-NN 0.946 0.946 0.951 0.932 Support vector machine (SVM)
0.975 0.986 0.969 0.978
Naive bayesian classifier 0.896 0.896 0.889 0.885 Logistic regression 0.902 0.893 0.897 0.890 Random forest 0.888 0.895 0.891 0.866
Table 3 Accuracy, precision, recall, and cross-accuracy results according to chatbot usage time variable Accuracy of the model
Cross accuracy
Precision of the model
Recall of the model
k-NN 0.849 0.849 0.849 1.00 Support vector machine 0.849 0.851 0.849 1.00 Naive Bayesian Classifier 0.849 0.849 0.849 1.00 Logistic regression 0.851 0.851 0.851 1.00 Random forest 0.637 0.851 0.637 1.00
13
23667


Current Psychology (2024) 43:23656–23674
of anxiety about using chatbots can affect their approval and use of chatbots. If a student has safety anxiety or performance anxiety about using a chatbot, they may be less likely to use it. Researchers (e.g. Lee et al., 2022) have noted that students often prefer to seek help from computer systems rather than teachers, especially students who are afraid to ask questions. The reasons in this case can also be applied to the self-efficacy finding. In other words, chatbots can help students understand the continuity of theory and practice and increase their confidence in learning and practicing by providing instant solutions to solve the problems they encounter. In this case, the intention to use chatbot can emphasize the importance and effectiveness of providing instant feedback to students to increase their self-efficacy and learning performance with the features offered by the chatbot.
No relationship was found between behavioral intention to use and learn chatbots and social influence (H4), facilitating conditions (H5a), chatbot system, information and service quality (H13), satisfaction with using chatbots (H14), and preference for interaction (H15). The effect of facilitating conditions and behavioral intention on the duration of chatbot usage was significant. Social influence indicates that users care about what their social circle thinks about using chatbots. The fact that students' social influence does not affect their intentions may be because they do not have a social environment experienced in using chatbots. Facilitating conditions, on the other hand, are related to the perceptions of having sufficient infrastructure to use the chatbot. The reason for this inconsistent finding may be that students have the necessary knowledge to use the chatbot, the system is readily available, and the system is easy to access.
Looking at the moderator effects, age was found to have a moderator effect on the path coefficient between performance expectation and behavioral intention to use/ learn chatbots (H9c). Natarajan et al. (2017) found that age affects the intention to use technology in terms of finding technology easier and more useful. In this context, age affects the relationship between performance expectation and intention in the context of the perception of convenience and usefulness. Gender, on the other hand, has a moderator effect on the path coefficient between performance and effort expectancy and behavioral intention to use/learn chatbots (H10a, b). Yildiz Durak (2019) emphasized that gender plays an important role in the behavior of adopting and using social media environments and that gender has psychological effects in the process of
Looking at Table 3, the algorithm with the highest accuracy result according to the chatbot usage time variable is the logistic regression algorithm (0.851). In the cross-correct results, support vector machine, logistic regression, and random forest (0.851) gave the most accurate results. The algorithm with the highest precision result is the logistic regression (0.851) algorithm. As a result of the sensitivity, all algorithms produce the result (1.00).
Discussion
This study aimed to predict the factors affecting the use of chatbot technologies utilizing PLS-SEM and machine learning algorithms in the context of the UTAUT2 framework of students who use chatbot technologies as an educational tool. As a result of the study, students' behavioral intention to use and learn chatbots significantly affected "performance expectancy (H1), effort expectancy (H2), attitude towards improving learning (H3), self-efficacy (H6), anxiety (H7), and chatbot confirmation and usage continuance (H12)”. Students may tend to use chatbots with expectations that using chatbots will improve their learning performance and beliefs that they will be rewarded for their efforts. If a learner thinks that he/she can access learning materials faster and more effectively through a chatbot, his/her performance expectation and effort expectation may increase. Terblanche and Kidd (2022) explain the importance of performance and effort expectancy over intent, as the expectation to get answers to the queries of chatbot users and to benefit from the effort spent interacting with such a system. In this context, the expectation of performance and effort on chatbot usage and learning intention is important in the context of these explanations.
Attitude and self-efficacy are the approaches, level of effort and belief in experiencing new experiences together, and resistance in coping with difficulties. Students' posi tive attitude towards chatbots and their confidence in their own self-efficacy may increase their intention to use chat bots. If a student believes that he/she can improve learning through a chatbot and is confident in their abilities, they may be more likely to use the chatbot. Therefore, it is an expected finding that it has a decisive effect on the intention to use. The anxiety is a concept that emphasizes users' anxiety about using and accepting technology, according to Mokmin and Ibrahim (2021). Students' level
13
23668


Current Psychology (2024) 43:23656–23674
This result is contrary to the current understanding of general technology use in the context of the relevant literature. However, the results of this study show that facilitating conditions and social impact are not considered important in the use of a chatbot. It is suggested that this should be considered in future research on chatbot design and use. It can be suggested to focus on studies that are sensitive to the context of use based on empirical research with measures to support performance and effort expectancy, attitude, self-efficacy and reduce anxiety in chatbot designs. From an application perspective, given that self-efficacy expectations play the strongest role in an individual's intent to use chatbots, chatbots' designs must be based on modeling that provides prelearning that supports self-efficacy. The present study has some limitations as well as important implications. First, research data were collected from students with background/experience in using chatbot technology. This indicates that caution should be exercised in generalizing the results of the study. However, future research may use different sampling techniques to explore the impact of chatbot technology on adoption by users who have experienced different levels of chatbot technology. Secondly, the quantitative approach was used in this research, which does not allow for an in-depth exploration of student views on the adoption of chatbots. Future work may use a mixed-method approach to build a deeper understanding. Finally, a database was created by measuring the adoption of chatbot technology with self-report data collection tools. Future research can compare results by discovering actual usage information. Future research should take a longitudinal approach to measure acceptance and use intentions and actual behavioral factors. The use of technology in teaching is a concept that can be affected by the experience of the instructor. In addition, their attitudes towards improving learning may change over time, depending on the individual, depending on their level of satisfaction with their level of achievement of the goal. By applying UTAUT2 at multiple time points, a more accurate description of acceptance and use intentions and behaviors can be made.
acceptance. The moderator effect of chatbot usage experience on the path coefficient between performance expectation and behavioral intention to use/learn chatbot is positive (H11a). Law et al. (2009) stated that the benefits and motivational aspects are effective for users in interactive systems. Følstad and Brandtzaeg (2020) emphasized that this also applies to the chatbot user experience. In particular, it draws attention to the pragmatic aspects of the user experience through useful and productive interactions. In this context, it is an expected result that the experience of using a chatbot has a moderator role in the relationship between the performance expectation and the intention obtained as a result of this study. In this study, support vector machine had the highest estimation accuracy according to the behavioral intention to use and learn chatbot variable, and logistic regression according to the chatbot usage time variable. In the literature, no study has been found on the UTAUT2 structure in the use of chatbots of machine learning algorithms. When the prediction results of PLS-SEM and machine learning algorithms are compared, both approaches produce high rates.
Conclusions, limitations, and recommendations
This research is an original study that seeks to understand the adoption of the use of chatbots in education, chatbot confirmation and usage continuance, and the impact of quality concerns on this issue. For this purpose, the UTAUT2 model is extended with variables such as chatbot confirmation and usage continuance, chatbot system, information and service quality, satisfaction, and interaction preference. Given the growing interest and environments in AI-powered chatbots, the inclusion of these constructs is considered important in future studies where user preferences come to the fore. The results showed some interesting behavior. Social influence and facilitating conditions did not have any direct effect on behavioral intention to use/learn chatbots.
13
23669


Current Psychology (2024) 43:23656–23674
Tables 4, 5, and 6
Appendix
Table 4 Factor loading Structures Dimensions/Items Factor loadings
Performance Expectancy
U1 0.940 U2 0.953 U3 0.954 Effort Expectancy U4 0.955 U5 0.955 U6 0.946 Attitude toward Improving Learning
U7 0.949 U8 0.952 U9 0.940 Social Influence U10 0.892 U11 0.908 U12 0.931 Facilitating conditions U13 0.898 U14 0.939 U15 0.888 Self-efficacy U16 0.936 U17 0.952 U18 0.942 Anxiety U19 0.896 U20 0.919 U21 0.910 Behavioral Intention to Use/Learn Chatbot
U22 0.933 U23 0.951 U24 0.956 Chatbot Confirmation and Usage Continuance
Confirmation 0.937 Comprehensibility 0.953 Reliability 0.943 Responsiveness 0.952 Trust 0.951 Interaction 0.955 Chatbot System, Information and Service Quality
Information quality 0.955 System quality 0.980 Service quality 0.966
Table 5 Construct reliability and validity Cronbach's alpha
Composite reliability (rho_a)
Composite reliability (rho_c)
The average variance extracted (AVE) Attitude toward Improving Learning 0.943 0.943 0.963 0.897 Anxiety 0.895 0.902 0.934 0.826 Behavioral Intention to Use/Learn Chatbot 0.942 0.942 0.963 0.897 Effort Expectancy 0.949 0.949 0.967 0.907 Facilitating Conditions 0.894 0.901 0.934 0.825 Performance Expectancy 0.945 0.945 0.965 0.901 Self-efficacy 0.938 0.939 0.960 0.889 Social Influence 0.897 0.900 0.936 0.829 Chatbot System, Information and Service Quality 0.965 0.966 0.977 0.935 Chatbot Confirmation and Usage Continuance 0.978 0.978 0.982 0.900
13
23670


Current Psychology (2024) 43:23656–23674
1 2 3 4 5 6 7 8 9 10 11 12
1. ATIE
2. An 0.345
3. BIULC 0.859 0.405
4. Chatbot Usage Time 0.320 0.105 0.334
5. Chatbot Usage Experience 0.163 0.024 0.160 0.325
6. EE 0.900 0.302 0.834 0.347 0.163
7. Interaction Preference 0.021 0.182 0.016 0.215 0.058 0.020
8. FC 0.900 0.430 0.868 0.361 0.169 0.900 0.041
9. Chatbot System and Information Quality 0.847 0.278 0.800 0.322 0.162 0.859 0.010 0.851
10. Chatbot Confirmation and Usage Continuance 0.852 0.292 0.827 0.343 0.185 0.867 0.015 0.874 0.900
11. Satisfaction 0.509 0.167 0.455 0.452 0.261 0.518 0.073 0.519 0.522 0.533
12. PE 0.900 0.320 0.831 0.346 0.167 0.900 0.009 0.898 0.848 0.856 0.544
13. SE 0.900 0.390 0.882 0.337 0.162 0.900 0.021 0.900 0.850 0.854 0.484 0.888
14. SI 0.808 0.500 0.747 0.288 0.115 0.772 0.087 0.878 0.720 0.740 0.408 0.766
15. Age 0.009 0.017 0.013 0.013 0.070 0.020 0.030 0.014 0.029 0.015 0.015 0.006
16. Gender 0.107 0.085 0.107 0.061 0.089 0.097 0.018 0.141 0.099 0.096 0.065 0.112
17. Gender x PE 0.475 0.171 0.430 0.200 0.160 0.498 0.022 0.468 0.419 0.429 0.302 0.564
18. Age x PE 0.010 0.061 0.020 0.029 0.007 0.003 0.007 0.013 0.010 0.010 0.015 0.020
19. Chatbot Usage Experience x PE 0.010 0.105 0.008 0.044 0.266 0.013 0.030 0.005 0.007 0.020 0.086 0.006
20. Gender x EE 0.514 0.195 0.465 0.198 0.169 0.551 0.043 0.512 0.434 0.448 0.307 0.509
21. Gender x SI 0.412 0.279 0.398 0.136 0.126 0.394 0.070 0.450 0.341 0.363 0.201 0.382
22. Age x EE 0.006 0.054 0.018 0.006 0.003 0.002 0.024 0.007 0.005 0.007 0.019 0.012
23. Age x SI 0.017 0.032 0.015 0.002 0.018 0.021 0.003 0.036 0.030 0.038 0.040 0.013
24. Chatbot Usage Experience x EE 0.022 0.115 0.016 0.037 0.236 0.026 0.039 0.022 0.020 0.034 0.086 0.013
25. Chatbot Usage Experience x SI 0.027 0.068 0.024 0.056 0.093 0.021 0.028 0.024 0.038 0.049 0.080 0.016
13 14 15 16 17 18 19 20 21 22 23 24
1. ATIE
2. An 9
3. BIULC
4. Chatbot Usage Time
5. Chatbot Usage Experience
6. EE
7. Interaction Preference
8. FC
9. Chatbot System and Information Quality
10. Chatbot Confirmation and Usage Continuance
11. Satisfaction
12. PE
13. SE
14. SI 0.793
Table 6 HTMT
13
23671


Current Psychology (2024) 43:23656–23674
Acknowledgements This study is derived from the first author's thesis under the supervision of the second author.
Funding Open access funding provided by the Scientific and Technological Research Council of Türkiye (TÜBİTAK).
Data availability The datasets generated during and/or analysed during the current study are available from the corresponding author on reasonable request.
Declarations
Conflict of interest None.
Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons. org/licenses/by/4.0/.
References
Aksu Dünya, B., & Yıldız Durak, H. (2023). Hi! Tell me how to do it: Examination of undergraduate students’ chatbot-integrated course experiences. Quality & Quantity, 1–16. https://doi.org/10.1007/ s11135-023-01800-x Almahri, F. A. J., Bell, D., & Merhi, M. (2020, March). Understanding student acceptance and use of chatbots in the United Kingdom universities: a structural equation modelling approach. In 2020 6th International Conference on Information Management (ICIM) (pp. 284–288). IEEE. Annamalai, N., Ab Rashid, R., Hashmi, U. M., Mohamed, M., Alqaryouti, M. H., & Sadeq, A. E. (2023). Using chatbots for English language learning in higher education. Computers and Education: Artificial Intelligence, 5, 100153.
Balakrishnan, J., Abed, S. S., & Jones, P. (2022). The role of metaUTAUT factors, perceived anthropomorphism, perceived intelligence, and social self-efficacy in chatbot-based services? Technological Forecasting and Social Change, 180, 121692.
Bandura, A. (1977). Self-efficacy: Toward a unifying theory of behavioral change. Psychological Review, 84(2), 191–215. Bandura, A. (1986). The explanatory and predictive scope of selfefficacy theory. Journal Ofsocial and Clinical Psychology, 4, 359–373. Bandura, A. (1989). Human agency in social cognitive theory. American Psychologist, 44(9), 1175–1184.
Bandura, A. (2012). On the functional properties of perceived selfefficacy revisited. Journal of Management, 38(1), 9–44.
Bii, P. K., Too, J. K., & Mukwa, C. W. (2018). Teacher Attitude towards Use of Chatbots in Routine Teaching. Universal Journal of Educational Research, 6(7), 1586–1597.
Breiman, L. (2001). Random Forests. Machine Learning, 45, 5–32.
13 14 15 16 17 18 19 20 21 22 23 24
15. Age 0.019 0.018
16. Gender 0.103 0.107 0.066
17. Gender x PE 0.440 0.392 0.023 0.139
18. Age x PE 0.008 0.014 0.111 0.028 0.054
19. Chatbot Usage Experience x PE 0.006 0.015 0.007 0.071 0.113 0.081
20. Gender x EE 0.471 0.414 0.012 0.123 0.902 0.039 0.100
21. Gender x SI 0.392 0.582 0.007 0.129 0.674 0.013 0.079 0.712
22. Age x EE 0.006 0.022 0.090 0.025 0.041 0.900 0.074 0.049 0.018
23. Age x SI 0.024 0.017 0.146 0.006 0.014 0.560 0.023 0.017 0.096 0.577
24. Chatbot Usage Experience x EE 0.022 0.022 0.002 0.079 0.098 0.071 0.900 0.089 0.088 0.095 0.060
25. Chatbot Usage Experience x SI 0.043 0.020 0.016 0.067 0.083 0.022 0.768 0.093 0.129 0.060 0.094 0.791
*PE Performance Expectancy, EE Effort Expectancy; ATIE Attitude towards Improving Learning; SI Social Influence; FC Facilitating conditions; SE Self efficacy; An Anxiety; BIULC
Behavioral Intention to Use/Learn Chatbot
Table 6 (continued)
13
23672


Current Psychology (2024) 43:23656–23674
Lee, Y. F., Hwang, G. J., & Chen, P. Y. (2022). Impacts of an AI-based cha bot on college students’ after-class review, academic performance, self-efficacy, learning attitude, and motivation. Educational Technology Research and Development, 70(5), 1843–1865. Li, L., Lee, K. Y., Emokpae, E., & Yang, S. B. (2021). What makes you continuously use chatbot services? Evidence from chinese online travel agencies. Electronic Markets, 31, 575–599. Liao, C., Palvia, P., & Lin, H. N. (2010). Stage antecedents of consumer online buying behavior. Electronic Markets, 20(1), 53–65. Luo, X., Tong, S., Fang, Z., & Qu, Z. (2019). Frontiers: Machines vs. humans: The impact of artificial intelligence chatbot disclosure on customer purchases. Marketing Science, 38(6), 937–947. Martín-Rodríguez, Ó., Fernández-Molina, J. C., Montero-Alonso, M. Á., & González-Gómez, F. (2015). The main components of satisfaction with e-learning. Technology, Pedagogy and Education, 24(2), 267–277. Melián-González, S., Gutiérrez-Taño, D., & Bulchand-Gidumal, J. (2021). Predicting the intentions to use chatbots for travel and tourism. Current Issues in Tourism, 24(2), 192–210.
Menon, D., & Shilpa, K. (2023). “Chatting with ChatGPT”: Analyzing the factors influencing users’ intention to Use the Open AI’s ChatGPT using the UTAUT model. Heliyon, 9(11), e20962.
Mohd Rahim, N. I., Iahad, A. N., Yusof, A. F., & Al-Sharafi, A. M. (2022). AI-based chatbots adoption model for higher-education institutions: A hybrid PLS-SEM-neural network modelling approach. Sustainability, 14(19), 12726. Mokmin, N. A. M., & Ibrahim, N. A. (2021). The evaluation of chatbot as a tool for health literacy education among undergraduate students. Education and Information Technologies, 26(5), 6033–6049. Natarajan, T., Balasubramanian, S. A., & Kasilingam, D. L. (2017). Understanding the intention to use mobile shopping applications and its influence on price sensitivity. Journal of Retailing and Consumer Services, 37, 8–22.
Nguyen, D. M., Chiu, Y. T. H., & Le, H. D. (2021). Determinants of continuance intention towards banks’ chatbot services in Vietnam: A necessity for sustainable development. Sustainability, 13(14), 7625. Ochoa, X., & Wise, A. F. (2021). Supporting the shift to digital with student-centered learning analytics. Educational Technology Research and Development, 69, 357–361.
Parasuraman, A., Zeithaml, V. A., & Berry, L. L. (1988). SERVQUAL: A multiple-item scale for measuring consumer perceptions of service quality. Journal of Retailing, 64(1), 12–40. Pérez, J. Q., Daradoumis, T., & Puig, J. M. M. (2020). Rediscovering the use of chatbots in education: A systematic literature review. Computer Applications in Engineering Education, 28(6), 1549–1565. Prentice, C., & Nguyen, M. (2021). Robotic service quality–Scale development and validation. Journal of Retailing and Consumer Services, 62, 102661.
Raffaghelli, J. E., Rodríguez, M. E., Guerrero-Roldán, A. E., & Baneres, D. (2022). Applying the UTAUT model to explain the students’ acceptance of an early warning system in Higher Education. Computers & Education, 182, 104468.
Ragheb, M. A., Tantawi, P., Farouk, N., & Hatata, A. (2022). Investigating the acceptance of applying chat-bot (Artificial intelligence) technology among higher education students in Egypt. International Journal of Higher Education Management, 8(2), 1–13. Raman, A., & Don, Y. (2013). Preservice teachers’ acceptance of learning management software: An application of the UTAUT2 model. International Education Studies, 6(7), 157–164.
Ramandanis, D., & Xinogalos, S. (2023). Investigating the Support Provided by Chatbots to Educational Institutions and Their
Celik, H. (2016). Customer online shopping anxiety within the Unified Theory of Acceptanceand Use Technology (UTAUT) framework. Asia Pacific Journal of Marketing and Logistics, 28, 278–307. Cortes, C., & Vapnik, V. (1995). Support-vector networks. Machine learning, 20, 273–297.
Crothers, L. M., Hughes, T. L., Kolbert, J. B., & Schmitt, A. J. (2020). Theory and cases in school-based consultation: A resource for school psychologists, school counselors, special educators, and other mental health professionals. Routledge.
Durak, H. Y., & Durak, A. (2020). Instructional technology and lifelong learning: trends, Opportunities and challenges in theses dealing with the use of technology in the context of lifelong learning [Öğretim teknolojisi ve hayat boyu öğrenme: Hayat boyu öğrenme bağlamında teknoloji kullanımını ele alan tezlerde ortaya çıkan eğilimler, fırsatlar ve zorluklar]. Instructional Technology and Lifelong Learning, 1(1), 88–106.
Følstad, A., & Brandtzaeg, P. B. (2020). Users’ experiences with chatbots: Findings from a questionnaire study. Quality and User Experience, 5(1), 3.
Fryer, L. K., Nakao, K., & Thompson, A. (2019). Chatbot learning partners: Connecting learning experiences, interest and competence. Computers in Human Behavior, 93, 279–289.
Gunasinghe, A., Abd Hamid, J., Khatibi, A., & Azam, S. F. (2019). Does anxiety impede VLE adoption intentions of state university lecturers?-a study based on modified UTAUT framework. European Journal of Social Sciences Studies, 4(4), 46–71.
Gunasinghe, A., & Nanayakkara, S. (2021). Role of technology anxiety within UTAUT in understanding non-user adoption intentions to virtual learning environments: The state university lecturers’ perspective. International Journal of Technology Enhanced Learning, 13(3), 284–308. Hair, J. F., Ringle, C. M., & Sarstedt, M. (2011). PLS-SEM: Indeed a Silver Bullet. Journal of Marketing Theory and Practice, 19(2), 139–152. https://doi.org/10.2753/MTP1069-6679190202 Hair, J. F., Hult, G. T. M., Ringle, C. M., Sarstedt, M., & Thiele, K. O. (2017). Mirror, mirror on the wall: A comparative evaluation of composite-based structural equation modeling methods. Journal of the Academy of Marketing Science, 45, 616–632.
Hair, J. F., Risher, J. J., Sarstedt, M., & Ringle, C. M. (2019). When to use and how to report the results of PLS-SEM. European Business Review, 31(1), 2–24. https://doi.org/10.1108/EBR-11-2018-0203 Henseler, J., Ringle, C. M., & Sarstedt, M. (2015). A new criterion for assessing discriminant validity in variance-based structural equation modeling. Journal of the Academy of Marketing Science, 43, 115–135. Hornbæk, K., & Hertzum, M. (2017). Technology acceptance and user experience: A review of the experiential component in HCI. ACM Transactions on Computer-Human Interaction (TOCHI), 24(5), 1–30.
Hwang, G. J., Xie, H., Wah, B. W., & Gašević, D. (2020). Vision, challenges, roles and research issues of Artificial Intelligence in Education. Computers and Education: Artificial Intelligence, 1, 100001.
Jowarder, M. I. (2023). The influence of ChatGPT on social science students: Insights drawn from undergraduate students in the United States. Indonesian Journal of Innovation and Applied Sciences (IJIAS), 3(2), 194–200.
Kasilingam, D. L. (2020). Understanding the attitude and intention to use smartphone chatbots for shopping. Technology in society, 62, 101280. Law, E. L.-C., Roto, V., Hassenzahl, M., Vermeeren, A.P., Kort, J. (2009) Understanding, scoping and defining user experience: a survey approach. In: Proceedings of the SIGCHI conference on human factors in computing system. ACM, New York, NY, pp 719–728.
13
23673


Current Psychology (2024) 43:23656–23674
recommender systems. Information Systems and e-Business Management, 13, 769–799.
Yildiz Durak, H. (2019). Examining the acceptance and use of online social networks by preservice teachers within the context of unified theory of acceptance and use of technology model. Journal of Computing in Higher Education, 31(1), 173–209.
Yildiz Durak, H. (2023). Conversational agent-based guidance: Examining the effect of chatbot usage frequency and satisfaction on visual design self-efficacy, engagement, satisfaction, and learner autonomy. Education and Information Technologies, 28(1), 471–488.
Yildiz Durak, H., & Onan, A. (2023a). Adaptation of chatbot confirmation and usage continuance scale into Turkish. In the 1st International Conference on Modern and Advanced Research. https:// doi.org/10.59287/icmar.1259 Yildiz Durak, H., & Onan, A. (2023b). An examination of studies on the use of chatbot technology in the field of education. In International Conference on Applied Engineering and Natural Sciences (Vol. 1, No. 1, pp. 121–124). https://doi.org/10.59287/icaens.978 Yildiz Durak, H., & Onan, A. (2023c). Turkish adaptation of the chatbot system, information and service quality scale. In International Conference on Applied Engineering and Natural Sciences (Vol. 1, No. 1, pp. 114–117). https://doi.org/10.59287/icaens.976 Yildiz Durak, H., & Onan, A. (2023d). Adaptation of Behavioral Intention to Use and Learn Chatbot in Education Scale into Turkish [Eğitimde Chatbot Kullanmaya ve Öğrenmeye Yönelik Davranışsal Niyet Ölçeğinin Türkçeye Uyarlanması]. Ahmet Keleşoğlu Eğitim Fakültesi Dergisi, 5(3), 1162–1172.
Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.
Students: A Systematic Literature Review. Multimodal Technologies and Interaction, 7(11), 103.
Ray S (2019) A quick review of machine learning algorithms. In: 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon). IEEE. 35–39.
Shah, H., Warwick, K., Vallverdú, J., & Wu, D. (2016). Can machines talk? Comparison of Eliza with modern dialogue systems. Computers in Human Behavior, 58, 278–295.
Sung, Y. T., Chang, K. E., & Liu, T. C. (2016). The effects of integrating mobile devices with teaching and learning on students’ learning performance: A meta-analysis and research synthesis. Computers & Education, 94, 252–275.
Terblanche, N., & Kidd, M. (2022). Adoption factors and moderating effects of age and gender that influence the intention to use a non-directive reflective coaching chatbot. SAGE Open, 12(2), 21582440221096136. Thomas, W. E., & David, O. M. (2017). Chapter 4—exploratory study. Research Methods for Cyber Security, Syngress, 95–130. https://doi.org/10.1016/B978-0-12-805349-2.00004-2
van der Goot, M. J., & Pilgrim, T. (2019). Exploring age differences in motivations for and acceptance of chatbot communication in a customer service context. In International Workshop on Chatbot Research and Design (pp. 173–186). Cham: Springer International Publishing. Venkatesh, V., Morris, M. G., Davis, G. B., & Davis, F. D. (2003). User acceptance of information technology: Toward a unified view. MIS Quarterly, 425–478. Venkatesh, V., Thong, J. Y. L., & Xu, X. (2012). Consumer Acceptance and Use of Information Technology: Extending the Unified Theory of Acceptance and Use of Technology. MIS Quarterly, 36(1), 157–178. Wang, Y. Y., Luse, A., Townsend, A. M., & Mennecke, B. E. (2015). Understanding the moderating roles of types of recommender systems and products on customer behavioral intention to use
13
23674